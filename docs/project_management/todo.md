# TODO

- [] create cuda environment
- [] install whisper and pyannote audio
- [] read more docs on whisper and pyannote audio
- [] create a prelabbeled dataset that is diarized to test on the pyannnote. audio
- [] get a transcription working on a test file
- [] use chuncking and the basis that the user will be first speaker to overlap and sync up the diarization with pyannote
- [] test accuracy of diarization with the audio file
- [] if not accurate enough fine tune the pyannote audio model to my own data
